{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*Analytical Information Systems*\n",
    "\n",
    "# Tutorial 6 - Predictive Modeling II\n",
    "\n",
    "Matthias Griebel<br>\n",
    "Lehrstuhl f√ºr Wirtschaftsinformatik und Informationsmanagement\n",
    "\n",
    "SS 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "toc": true
   },
   "source": [
    "<h1>Agenda<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Modeling\" data-toc-modified-id=\"Modeling-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Modeling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models-for-supervised-learning\" data-toc-modified-id=\"Models-for-supervised-learning-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Models for supervised learning</a></span></li><li><span><a href=\"#Metrics-for-regression\" data-toc-modified-id=\"Metrics-for-regression-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Metrics for regression</a></span></li></ul></li><li><span><a href=\"#Up-to-you:--Price-forecasting-for-used-cars\" data-toc-modified-id=\"Up-to-you:--Price-forecasting-for-used-cars-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Up to you:  Price forecasting for used cars</a></span></li><li><span><a href=\"#Exam-Questions\" data-toc-modified-id=\"Exam-Questions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Exam Questions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Exam-AIS-SS-2018\" data-toc-modified-id=\"Exam-AIS-SS-2018-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Exam AIS SS 2018</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Recap: CRISP-DM__\n",
    "<img align=\"right\" src=\"http://statistik-dresden.de/wp-content/uploads/2012/04/CRISP-DM_Process_Diagram1.png\" style=\"width:50%\">\n",
    "\n",
    "Today, we will focus on \n",
    "- `Data Preparation`\n",
    "- `Modeling` for regression tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Models for supervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`parsnip` contains wrappers for a number of [models](https://tidymodels.github.io/parsnip/articles/articles/Models.html). \n",
    "\n",
    "- Classification\n",
    "    - Regression: `logistic_reg()`,  `multinom_reg()`\n",
    "    - Tree based:`decision_tree()`, `rand_forest()`, `boost_tree()`\n",
    "    - ANN: `mlp()`\n",
    "    - KNN: `nearest_neighbor()`\n",
    "    - SVM: `svm_poly()`, `svm_rbf()`\n",
    "\n",
    "- Regression\n",
    "    - Regression: `linear_reg()`\n",
    "    - Tree based: `decision_tree()`, `rand_forest()`, `boost_tree()`\n",
    "    - ANN: `mlp()`\n",
    "    - KNN: `nearest_neighbor()`\n",
    "    - SVM: `svm_poly()`, `svm_rbf()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__LightGBM__\n",
    "\n",
    "[LightGBM](https://lightgbm.readthedocs.io/en/latest/) is a gradient boosting framework that uses tree based learning algorithms\n",
    "\n",
    "- Faster training speed and higher efficiency\n",
    "- Lower memory usage\n",
    "- Better accuracy\n",
    "- Support of parallel and GPU learning\n",
    "- Capable of handling large-scale data\n",
    "\n",
    "But: not yet supported by `parsnip`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Metrics for regression\n",
    "\n",
    "There are several metrics for evaluating regression models. As with classification metrics, the `yardstick` package contains all common regression metrics.\n",
    "\n",
    "\n",
    "*Note: We define $x_i$ as the actual value and $y_i$ as the predicted value*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "__Mean absolute error (MAE)__ \n",
    "\n",
    "$\\frac{1}{n}\\sum_{i=1}^{n}|x_i-y_i|$ \n",
    "\n",
    "- absolute difference between $yi$ and $xi$\n",
    "- good interpretability "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Root-mean-square error (RMSE)__\n",
    "\n",
    "$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i-y_i)^2}$\n",
    "\n",
    "- square root of the average of squared errors (MSE)\n",
    "- proportional to the size of the squared error: larger errors have a disproportionately large effect "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Coefficient of determination ($R^2$)__\n",
    "\n",
    "<img align=\"center\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/6b863cb70dd04b45984983cb6ed00801d5eddc94\" style=\"width:15%\">\n",
    "\n",
    "<img align=\"center\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/86/Coefficient_of_Determination.svg/600px-Coefficient_of_Determination.svg.png\" style=\"width:30%\">\n",
    "\n",
    "where \n",
    "\n",
    "sum of squares of residuals:\n",
    "$SS_{tot} = \\sum_{i}(x_i - \\bar{x})^2$ \n",
    "\n",
    "total sum of squares:\n",
    "$SS_{res} = \\sum_{i}(x_i - y_i)^2$ \n",
    "\n",
    "- proportion of the variance in the dependent variable that is predictable from the independent variable(s)\n",
    "- usually between 0 and 1\n",
    "\n",
    "Source: [Wikipedia](https://en.wikipedia.org/wiki/Coefficient_of_determination)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Mean Absolute Percentage Error (MAPE)__\n",
    "\n",
    "$\\frac{100\\%}{n}\\sum_{i=1}^{n}\\left |\\frac{x_i-y_i}{x_i}\\right|$\n",
    "\n",
    "- frequently used for (time series) forecasting\n",
    "- cannot be used if there are zero values\n",
    "- puts a heavier penalty on negative errors (biased: systematically select a method whose forecasts are too low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Up to you:  Price forecasting for used cars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Kaggle used cars database__\n",
    "\n",
    "Over 370,000 used cars scraped from Ebay Kleinanzeigen. See description on [Kaggle.com](https://www.kaggle.com/orgesleka/used-cars-database)\n",
    "\n",
    "\n",
    "Why is that interesting?\n",
    "\n",
    "<img align=\"center\" src=\"images/06/wkda.png\" style=\"width:80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Load required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidymodels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "autos <- read_csv('data/T06/autos.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "autos %>%\n",
    "  glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Up to you: Price forecasting for used cars__\n",
    "\n",
    "Build a regression model that predicts the price for used cars\n",
    "\n",
    "1. Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autos_split <- initial_split(autos, prop = 3/4)\n",
    "train_set <- training(autos_split)\n",
    "test_set <- testing(autos_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Up to you: Price forecasting for used cars__\n",
    "\n",
    "2. Prepare a recipe for data preprocessing, removing outliers or inconsistencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set %>%\n",
    "    recipe(price ~ vehicleType + yearOfRegistration + gearbox + powerPS\n",
    "                   + kilometer + fuelType + brand) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check Prices*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(is.na(train_set$price))\n",
    "options(repr.plot.width=7, repr.plot.height=3)\n",
    "options(scipen=999)\n",
    "train_set %>%\n",
    "  ggplot(aes(x=vehicleType, y=price)) + geom_boxplot() + ylim(0,1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some outliers need to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_price <- quantile(train_set$price, probs = c(0.01, 0.05, 0.95, 0.99))\n",
    "quantiles_price\n",
    "train_set %>%\n",
    "  filter(price >= quantiles_price[1], price <= quantiles_price[4]) %>%\n",
    "  ggplot(aes(x=vehicleType, y=price)) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>%\n",
    "    step_filter(price >= quantiles_price[2], price <= quantiles_price[4]) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check vehicle type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(train_set$vehicleType)\n",
    "table(train_set$vehicleType)\n",
    "sum(is.na(train_set$vehicleType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>%\n",
    "    step_naomit(vehicleType) %>%\n",
    "    step_dummy(vehicleType) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check power*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set %>%\n",
    "  ggplot(aes(x=vehicleType, y=powerPS)) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles_power <- quantile(train_set$powerPS, probs = c(0.05, 0.1, 0.15, 0.95, 0.99))\n",
    "quantiles_power\n",
    "train_set %>%\n",
    "  filter(powerPS > 0, powerPS <= quantiles_power[4]) %>%\n",
    "  ggplot(aes(x=vehicleType, y=powerPS)) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>%\n",
    "    step_filter(powerPS > 0, powerPS <= quantiles_power[4]) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check year of registration*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set$yearOfRegistration %>% summary()\n",
    "train_set %>%\n",
    "  filter(yearOfRegistration > 1900, yearOfRegistration <= 2016) %>%\n",
    "  ggplot(aes(x=vehicleType, y=yearOfRegistration)) + geom_boxplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>%\n",
    "    step_filter(yearOfRegistration > 1950, yearOfRegistration <= 2016) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check fuel type*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "unique(train_set$fuelType)\n",
    "table(train_set$fuelType)\n",
    "sum(is.na(train_set$fuelType))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>%\n",
    "    #step_knnimpute(fuelType) %>%\n",
    "    step_naomit(fuelType) %>%\n",
    "    step_other(fuelType, threshold = 0.01) %>%\n",
    "    step_dummy(fuelType) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check gearbox*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique(train_set$gearbox)\n",
    "table(train_set$gearbox)\n",
    "sum(is.na(train_set$gearbox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>%\n",
    "    step_naomit(gearbox) %>%\n",
    "    step_dummy(gearbox) -> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check brand*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set %>% distinct(brand) %>% pull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Add findings to recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "german_brands = c('volkswagen', 'audi', 'bmw', 'mercedes_benz', 'porsche','opel')\n",
    "rec %>%\n",
    "    step_mutate(brand=if_else(brand %in% german_brands, 'german', 'foreign')) %>%\n",
    "    step_string2factor(brand) %>%\n",
    "    step_dummy(brand)-> rec\n",
    "rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Check Kilometer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_set %>%\n",
    "  ggplot(aes(x=vehicleType, y=kilometer)) + geom_boxplot()\n",
    "unique(train_set$kilometer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Prepare recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rec %>% \n",
    "    check_missing(all_predictors()) %>%\n",
    "    prep() -> prepped_rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Bake train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "train_set_baked <- prepped_rec %>% juice()\n",
    "test_set_baked <- prepped_rec %>% bake(new_data=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set_baked %>% head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "__Up to you: Price forecasting for used cars__\n",
    "\n",
    "3. Fit and evaluate two different models on the train set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*Linear Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_reg(mode = 'regression') %>%\n",
    "    set_engine('lm') %>%\n",
    "    fit(price ~ ., data = train_set_baked) %>%\n",
    "    predict(new_data = test_set_baked) %>%\n",
    "    cbind(truth = test_set_baked$price) %>%\n",
    "    metrics(truth, .pred) -> res_lin\n",
    "res_lin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "*XGBoost* (detailed  [parameters](https://xgboost.readthedocs.io/en/latest/parameter.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boost_tree(mode=\"regression\", tree_depth = 6, learn_rate = 0.3) %>%\n",
    "    set_engine('xgboost') %>%\n",
    "    fit(price ~ ., data = train_set_baked) %>%\n",
    "    predict(new_data = test_set_baked) %>%\n",
    "    cbind(truth = test_set_baked$price) %>%\n",
    "    metrics(truth, .pred) -> res_xgb\n",
    "res_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Exam Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exam AIS SS 2018\n",
    "\n",
    "__Question 5: Supervised Learning__\n",
    "\n",
    "(a) (3 points) Overfitting is a key problem which arises in supervised learning. Explain the central underlying trade-off using a simple plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "> <img src=\"http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png\" style=\"width:70%\">\n",
    " Source: http://scott.fortmann-roe.com/docs/docs/BiasVariance/biasvariance.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(b) (2 points) For each of the following machine learning approaches name a measure / algorithm variant which allows controlling over-fitting tendencies. You should only consider measures which are specific to this algorithm  (i.e., not cross-validation or other generic approaches)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Pre-Pruning (Early Stopping Rule): Stop the algorithm before it becomes a fully-grown tree\n",
    "- Post-pruning: Grow decision tree to its entirety, then trim the nodes of the decision tree in a bottom-up fashion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - _increase_ k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Boosting Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Learning Rate\n",
    "- other hyperparameters, i.e., number of boosting rounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Limit the number of independent variables\n",
    "- Ridge: Penalize by sum-of-squares of parameters\n",
    "- Lasso: Penalize by sum-of-absolute values of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(c) __Support Vector Machines__\n",
    "A certain kind of SVM is characterized by the following optimization problem:\n",
    "\n",
    "$$\\min \\underbrace{\\frac{1}{2} w^Tw}_{A} + \\underbrace{C \\sum_k \\epsilon_k}_{B}$$\n",
    "subject to\n",
    "$$y_i (wx_i+b) \\geq 1 - \\epsilon_i$$\n",
    "\n",
    "i. (2 points) What kind of SVM is described here? Provide an intuition of the role of $\\epsilon$ in the constraint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - Soft Margin SVM\n",
    "- Slack variables $\\epsilon_i$ can be added to allow misclassification of difficult or noisy examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "ii.  (2 points)  Briefly explain the two parts A and B of the objective function.\n",
    "\n",
    "$$\\min \\underbrace{\\frac{1}{2} w^Tw}_{A} + \\underbrace{C \\sum_k \\epsilon_k}_{B}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A: Margin between hyperplanes\n",
    "\n",
    "> B: Penalty term for misclassification, parameter C is a regularization parameter to control overfitting,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(d)  (2 points)  Briefly explain the concept of bootstrap aggregation (bagging) and how it benefits supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Create ensembles of weak learners by repeatedly randomly resampling the training data\n",
    "-  Given a training set of size n, create m samples of size n by drawing n examples from the original data, with replacement \n",
    "- Create m models from m samples\n",
    "- Combine the m resulting models using simple majority vote (classification) or averaging (regression)\n",
    "\n",
    "> Decreases error by decreasing the variance in the results due to unstable learners, bias remains unchanged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "(e)  (2 points)  How  would  you  assess  the  relative  importance  of  variables  in  a  random forest.  Explain your answer. (You may consider the next question for an illustration.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "From (f) - See Tutorial 5\n",
    "<img align=\"center\" src=\"images/05/rf.png\" style=\"width:60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Solution (e)\n",
    "\n",
    "> Number of splits (across all tress) that include the feature renders the feature more important (*Sex*: 3, *Age/Pclass*: 2); Position of split matters as well (first split always *Sex* - high information gain) \n",
    "\n",
    ">Not in lecture: \n",
    "- Gini Importance / Mean Decrease in Impurity (MDI)\n",
    "    - Calculate the sum over the number of splits (across all tress) that include the feature, proportionally to the number of samples it splits.\n",
    "- Permutation Importance or Mean Decrease in Accuracy (MDA) \n",
    "\n",
    ">see (https://medium.com/the-artificial-impostor/feature-importance-measures-for-tree-models-part-i-47f187c1a2c3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.0"
  },
  "rise": {
   "enable_chalkboard": false,
   "overlay": "<div class='logo'><img src='images/uniwue4c.png'></div>",
   "scroll": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Agenda",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
